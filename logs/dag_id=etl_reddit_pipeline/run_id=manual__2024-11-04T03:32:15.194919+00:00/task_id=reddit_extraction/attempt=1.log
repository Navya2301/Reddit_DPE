[2024-11-04T03:32:16.822+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-11-04T03:32:16.844+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-11-04T03:32:15.194919+00:00 [queued]>
[2024-11-04T03:32:16.851+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-11-04T03:32:15.194919+00:00 [queued]>
[2024-11-04T03:32:16.851+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2024-11-04T03:32:16.861+0000] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): reddit_extraction> on 2024-11-04 03:32:15.194919+00:00
[2024-11-04T03:32:16.868+0000] {standard_task_runner.py:72} INFO - Started process 73 to run task
[2024-11-04T03:32:16.883+0000] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_extraction', 'manual__2024-11-04T03:32:15.194919+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/reddit_dag.py', '--cfg-path', '/tmp/tmp65brjik5']
[2024-11-04T03:32:16.888+0000] {standard_task_runner.py:105} INFO - Job 8: Subtask reddit_extraction
[2024-11-04T03:32:16.948+0000] {task_command.py:467} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_extraction manual__2024-11-04T03:32:15.194919+00:00 [running]> on host 09b173f4cbfb
[2024-11-04T03:32:17.028+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Navya Racha' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-11-04T03:32:15.194919+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-04T03:32:15.194919+00:00'
[2024-11-04T03:32:17.030+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-11-04T03:32:17.045+0000] {logging_mixin.py:190} WARNING - Version 7.8.0 of praw is outdated. Version 7.8.1 was released Friday October 25, 2024.
[2024-11-04T03:32:17.049+0000] {logging_mixin.py:190} INFO - Connected to Reddit!
[2024-11-04T03:32:17.546+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I recently came across an [article](https://medium.com/@pepitoscrespo/why-most-popular-programming-books-are-ruining-your-skills-a44c7fed880d) by Jose Crespo. The author argues that many well-known programming books‚Äîlike Clean Code, The Pragmatic Programmer, and Design Patterns ‚Äîmay actually hinder your development rather than help it. Here are the main points he discusses:\n\n**Over-Engineering for Hypothetical Scenarios:**\n\n* These books often advise designing code for future changes, leading to over-engineered and abstract code that's hard to read and maintain.\n* Instead, it's better to focus on solving current problems with simple, modular code and avoid unnecessary complexity.\n\n**Impracticality of Top-Down Code Reading:**\n\n*  The idea of writing code that's readable from top to bottom doesn't align with real-world debugging, where developers jump into specific areas and trace code from the bottom up.\n* Code should be designed to make tracing and debugging more straightforward, not like reading a novel.\n\n**Misuse of Object-Oriented Programming (OOP):**\n\n* An overemphasis on OOP principles can result in a tangled web of subclasses and inheritance hierarchies.\n* This complexity makes the codebase difficult to debug and maintain, often requiring runtime analysis to understand.\n\n**Overdependence on a Single Language:**\n\n* Focusing too much on mastering one programming language can make developers less adaptable in a fast-evolving tech landscape.\n* With AI tools that can handle syntax, understanding fundamental concepts like algorithms and system architecture is more valuable.\n\n**Premature Optimization Pitfalls:**\n\n* Early optimization efforts can complicate code without significant performance gains.\n* Writing clear, maintainable code should be the priority; optimize later when necessary.\n\n**Challenges with Dynamic Runtime Analysis:**\n\n* Over-engineered code often requires time-consuming dynamic runtime analysis to debug due to complex execution paths.\n* Simplifying code structure can save valuable time and reduce frustration during debugging.\n\n**The SOLID Principles Trap**\n\n* Strict adherence to principles like SOLID can isolate critical error information, making debugging more difficult.\n* It's important to balance these principles with practical considerations to maintain code that is both robust and understandable.\n\n**Which of the points do you agree with and which do you disagree with?**", 'author_fullname': 't2_7i6hswxy', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Why Popular Programming Books Might Be Ruining Your Skills', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gih13v', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.85, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 104, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 104, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730616281.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I recently came across an <a href="https://medium.com/@pepitoscrespo/why-most-popular-programming-books-are-ruining-your-skills-a44c7fed880d">article</a> by Jose Crespo. The author argues that many well-known programming books‚Äîlike Clean Code, The Pragmatic Programmer, and Design Patterns ‚Äîmay actually hinder your development rather than help it. Here are the main points he discusses:</p>\n\n<p><strong>Over-Engineering for Hypothetical Scenarios:</strong></p>\n\n<ul>\n<li>These books often advise designing code for future changes, leading to over-engineered and abstract code that&#39;s hard to read and maintain.</li>\n<li>Instead, it&#39;s better to focus on solving current problems with simple, modular code and avoid unnecessary complexity.</li>\n</ul>\n\n<p><strong>Impracticality of Top-Down Code Reading:</strong></p>\n\n<ul>\n<li> The idea of writing code that&#39;s readable from top to bottom doesn&#39;t align with real-world debugging, where developers jump into specific areas and trace code from the bottom up.</li>\n<li>Code should be designed to make tracing and debugging more straightforward, not like reading a novel.</li>\n</ul>\n\n<p><strong>Misuse of Object-Oriented Programming (OOP):</strong></p>\n\n<ul>\n<li>An overemphasis on OOP principles can result in a tangled web of subclasses and inheritance hierarchies.</li>\n<li>This complexity makes the codebase difficult to debug and maintain, often requiring runtime analysis to understand.</li>\n</ul>\n\n<p><strong>Overdependence on a Single Language:</strong></p>\n\n<ul>\n<li>Focusing too much on mastering one programming language can make developers less adaptable in a fast-evolving tech landscape.</li>\n<li>With AI tools that can handle syntax, understanding fundamental concepts like algorithms and system architecture is more valuable.</li>\n</ul>\n\n<p><strong>Premature Optimization Pitfalls:</strong></p>\n\n<ul>\n<li>Early optimization efforts can complicate code without significant performance gains.</li>\n<li>Writing clear, maintainable code should be the priority; optimize later when necessary.</li>\n</ul>\n\n<p><strong>Challenges with Dynamic Runtime Analysis:</strong></p>\n\n<ul>\n<li>Over-engineered code often requires time-consuming dynamic runtime analysis to debug due to complex execution paths.</li>\n<li>Simplifying code structure can save valuable time and reduce frustration during debugging.</li>\n</ul>\n\n<p><strong>The SOLID Principles Trap</strong></p>\n\n<ul>\n<li>Strict adherence to principles like SOLID can isolate critical error information, making debugging more difficult.</li>\n<li>It&#39;s important to balance these principles with practical considerations to maintain code that is both robust and understandable.</li>\n</ul>\n\n<p><strong>Which of the points do you agree with and which do you disagree with?</strong></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?auto=webp&s=5a14edf2ab3becb7069b960e332a94fc37db888a', 'width': 1200, 'height': 675}, 'resolutions': [{'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?width=108&crop=smart&auto=webp&s=f15ca506c3904fdae6659a0a4cef1b704ee675e6', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?width=216&crop=smart&auto=webp&s=c3455add605c8344dd6e87db093cf0c36bf73b04', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?width=320&crop=smart&auto=webp&s=d9a6d3a17765bd7ca243ca05916cdbbc21564360', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?width=640&crop=smart&auto=webp&s=93eb2da14f1082e777927b1065c26bf99362e404', 'width': 640, 'height': 360}, {'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?width=960&crop=smart&auto=webp&s=f26100b77adadbed5826759eb208060db8ef75cd', 'width': 960, 'height': 540}, {'url': 'https://external-preview.redd.it/6OqmKFqINVPbH-AIAgOiy5zzRGfxOfH3iG8ZwOe5zNg.jpg?width=1080&crop=smart&auto=webp&s=818bb6bff07630ecfaf093574abe30173ffca268', 'width': 1080, 'height': 607}], 'variants': {}, 'id': 'J_zuQmzxfcZoJKiMmOJ6P1SoFY_JaRbZ6oOp8zBgzMM'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gih13v', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Xavio_M'), 'discussion_type': None, 'num_comments': 38, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gih13v/why_popular_programming_books_might_be_ruining/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gih13v/why_popular_programming_books_might_be_ruining/', 'subreddit_subscribers': 226170, 'created_utc': 1730616281.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.548+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_1c6f704', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'I created a free data engineering email course.', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 73, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gim2i5', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': 'transparent', 'ups': 68, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': '9ecf3c88-e787-11ed-957e-de1616aeae13', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 68, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/2oCBuCpH1A-gdA491hsPcPoGTpiRGgP3-19YAA3N65c.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1730638057.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'datagibberish.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://datagibberish.com/p/free-data-engineering-course', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/7FC87eTceZyZ7xcTR-n_tKakJV1uCOFnFNONcl-wwco.jpg?auto=webp&s=d58619dbfba3eea94dbc9495fb772c6ff12cf7c7', 'width': 920, 'height': 480}, 'resolutions': [{'url': 'https://external-preview.redd.it/7FC87eTceZyZ7xcTR-n_tKakJV1uCOFnFNONcl-wwco.jpg?width=108&crop=smart&auto=webp&s=fb5c272f5034dc30f67a610f4c6e34886ce8e4f3', 'width': 108, 'height': 56}, {'url': 'https://external-preview.redd.it/7FC87eTceZyZ7xcTR-n_tKakJV1uCOFnFNONcl-wwco.jpg?width=216&crop=smart&auto=webp&s=b3b46656bd63e1207bfb5e82229c808074b0c5de', 'width': 216, 'height': 112}, {'url': 'https://external-preview.redd.it/7FC87eTceZyZ7xcTR-n_tKakJV1uCOFnFNONcl-wwco.jpg?width=320&crop=smart&auto=webp&s=a36863020c3f8a2029a007b6184082be349c6284', 'width': 320, 'height': 166}, {'url': 'https://external-preview.redd.it/7FC87eTceZyZ7xcTR-n_tKakJV1uCOFnFNONcl-wwco.jpg?width=640&crop=smart&auto=webp&s=633507c70232a2522cdc857315570388ae824632', 'width': 640, 'height': 333}], 'variants': {}, 'id': 'VqCIzCIjcZQZlYMAzH4UEi7ycGwdfcxRQYXN_O6jXgE'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineering Manager', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1gim2i5', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ivanovyordan'), 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1gim2i5/i_created_a_free_data_engineering_email_course/', 'stickied': False, 'url': 'https://datagibberish.com/p/free-data-engineering-course', 'subreddit_subscribers': 226170, 'created_utc': 1730638057.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.549+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi everyone!\n\nI was curious to know, which transition do you find more time-consuming and effort-intensive? On one hand, the bronze layer requires handling multiple sources, which can become complex and messy when dealing with a high volume. On the other hand, the silver-to-gold transition often demands adjustments based on evolving business needs from stakeholders, which can add its own challenges.\n\nI'd love to hear your thoughts on which stage you find more demanding and why!", 'author_fullname': 't2_7dic4iqx', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Bronze -> Silver vs. Silver-> Gold, which is more sh*t?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gipkqh', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 32, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 32, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730648167.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi everyone!</p>\n\n<p>I was curious to know, which transition do you find more time-consuming and effort-intensive? On one hand, the bronze layer requires handling multiple sources, which can become complex and messy when dealing with a high volume. On the other hand, the silver-to-gold transition often demands adjustments based on evolving business needs from stakeholders, which can add its own challenges.</p>\n\n<p>I&#39;d love to hear your thoughts on which stage you find more demanding and why!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gipkqh', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='gangana3'), 'discussion_type': None, 'num_comments': 39, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gipkqh/bronze_silver_vs_silver_gold_which_is_more_sht/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gipkqh/bronze_silver_vs_silver_gold_which_is_more_sht/', 'subreddit_subscribers': 226170, 'created_utc': 1730648167.0, 'num_crossposts': 1, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.549+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I recently learned about how the parquet format allows you to write statistics at the page level stored in the footer, which serves as a column index that allows for optimized reads with filters. And this is different from the typical predicate pushdown that occurs with row groups. (someone please correct me if im wrong) \n\nIm having trouble understanding how widespread this feature is in various readers/writers. From my understanding apache spark and impala added support for them when reading and writing. \n\nHowever I couldnt find clear information about the following technologies: \n\nAws Athena : Trino supports reading it i think but im not sure if that feature made its way to Athena\n\nPyarrow : i believe i saw they support writing column indexes but not reading them\n\nPandas\n\nThanks', 'author_fullname': 't2_ghmbml1ds', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Which technologies support Parquets column index feature', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gj0mv9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.81, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730676971.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I recently learned about how the parquet format allows you to write statistics at the page level stored in the footer, which serves as a column index that allows for optimized reads with filters. And this is different from the typical predicate pushdown that occurs with row groups. (someone please correct me if im wrong) </p>\n\n<p>Im having trouble understanding how widespread this feature is in various readers/writers. From my understanding apache spark and impala added support for them when reading and writing. </p>\n\n<p>However I couldnt find clear information about the following technologies: </p>\n\n<p>Aws Athena : Trino supports reading it i think but im not sure if that feature made its way to Athena</p>\n\n<p>Pyarrow : i believe i saw they support writing column indexes but not reading them</p>\n\n<p>Pandas</p>\n\n<p>Thanks</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gj0mv9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='mendysTherapist'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gj0mv9/which_technologies_support_parquets_column_index/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gj0mv9/which_technologies_support_parquets_column_index/', 'subreddit_subscribers': 226170, 'created_utc': 1730676971.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.550+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hey DE community! üëã  I have a background in data engineering, but I‚Äôm new to the LLM space. After reading this [AWS blog post](https://aws.amazon.com/blogs/machine-learning/automate-fine-tuning-of-llama-3-x-models-with-the-new-visual-designer-for-amazon-sagemaker-pipelines/) about using Amazon SageMaker‚Äôs new Visual Designer for fine-tuning Llama 3.x models recently, I had a few questions come up based on my past experience:\n\n* In real-world scenarios, is there often a need to fine-tune an LLM on a daily or weekly basis?\n* Is the ‚ÄúVisual Designer for Pipelines‚Äù just a buzzworthy feature, or does it actually improve productivity? I feel like the most efficient workflows in IT are usually code-based, not UI-driven.\n* This blog seems to show a ‚Äúhappy path‚Äù example where everything looks straightforward. What real-world challenges might teams face with this kind of use case? Do AWS products actually help address these challenges?\n\nWould love to hear any personal or team experiences or tips you might have when working on the real world  LLMs products.\n\nThanks!', 'author_fullname': 't2_274rubye', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Real world  LLMs products building experience', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gir1x7', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.63, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730652018.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hey DE community! üëã  I have a background in data engineering, but I‚Äôm new to the LLM space. After reading this <a href="https://aws.amazon.com/blogs/machine-learning/automate-fine-tuning-of-llama-3-x-models-with-the-new-visual-designer-for-amazon-sagemaker-pipelines/">AWS blog post</a> about using Amazon SageMaker‚Äôs new Visual Designer for fine-tuning Llama 3.x models recently, I had a few questions come up based on my past experience:</p>\n\n<ul>\n<li>In real-world scenarios, is there often a need to fine-tune an LLM on a daily or weekly basis?</li>\n<li>Is the ‚ÄúVisual Designer for Pipelines‚Äù just a buzzworthy feature, or does it actually improve productivity? I feel like the most efficient workflows in IT are usually code-based, not UI-driven.</li>\n<li>This blog seems to show a ‚Äúhappy path‚Äù example where everything looks straightforward. What real-world challenges might teams face with this kind of use case? Do AWS products actually help address these challenges?</li>\n</ul>\n\n<p>Would love to hear any personal or team experiences or tips you might have when working on the real world  LLMs products.</p>\n\n<p>Thanks!</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/9CD4O-8UZdNMXXLlJ8aKPl5z0nM1SpZ36xw2UG13Sdk.jpg?auto=webp&s=fcacb880a5b16e21e362eef970176610d80d13d7', 'width': 1025, 'height': 576}, 'resolutions': [{'url': 'https://external-preview.redd.it/9CD4O-8UZdNMXXLlJ8aKPl5z0nM1SpZ36xw2UG13Sdk.jpg?width=108&crop=smart&auto=webp&s=37c48677c45e82072106706d044f45253feedd4d', 'width': 108, 'height': 60}, {'url': 'https://external-preview.redd.it/9CD4O-8UZdNMXXLlJ8aKPl5z0nM1SpZ36xw2UG13Sdk.jpg?width=216&crop=smart&auto=webp&s=2a58cb965a4cdb63354277897c2317b3a0ed4ef6', 'width': 216, 'height': 121}, {'url': 'https://external-preview.redd.it/9CD4O-8UZdNMXXLlJ8aKPl5z0nM1SpZ36xw2UG13Sdk.jpg?width=320&crop=smart&auto=webp&s=99c5eaecc24c56478c0b3110daa83459d37e7fc6', 'width': 320, 'height': 179}, {'url': 'https://external-preview.redd.it/9CD4O-8UZdNMXXLlJ8aKPl5z0nM1SpZ36xw2UG13Sdk.jpg?width=640&crop=smart&auto=webp&s=097a608cea65b33d617d729fcde106a808b5e443', 'width': 640, 'height': 359}, {'url': 'https://external-preview.redd.it/9CD4O-8UZdNMXXLlJ8aKPl5z0nM1SpZ36xw2UG13Sdk.jpg?width=960&crop=smart&auto=webp&s=636209eeeadd3a511dcc1a7e367ba985e113154c', 'width': 960, 'height': 539}], 'variants': {}, 'id': 'ghYOsKCDXIIoJSidoDZta87v5LFr_9ceURjoq4RvK-8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1gir1x7', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='aid129'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gir1x7/real_world_llms_products_building_experience/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gir1x7/real_world_llms_products_building_experience/', 'subreddit_subscribers': 226170, 'created_utc': 1730652018.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.551+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Just joined a project temporarily, the guy managing it wrote custom UDFs to calculate period over period values (never heard of a window function??), has multiple data types stored in a single column, and formats display values (including arrow emojis) in his SQL query ü§£ü§£ü§£', 'author_fullname': 't2_gff2b', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Incompetent manager tales ?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1givyp9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.78, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730664590.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Just joined a project temporarily, the guy managing it wrote custom UDFs to calculate period over period values (never heard of a window function??), has multiple data types stored in a single column, and formats display values (including arrow emojis) in his SQL query ü§£ü§£ü§£</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1givyp9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='tiggat'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1givyp9/incompetent_manager_tales/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1givyp9/incompetent_manager_tales/', 'subreddit_subscribers': 226170, 'created_utc': 1730664590.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.552+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_akr18p9k', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Building ‚ÄúAuto-Analyst‚Äù ‚Äî A data analytics AI agentic system', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 79, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1gihj0t', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.5, 'author_flair_background_color': None, 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/YSjMer3PJLCrck7hgMIu74PpU-FgmQmPQG8WMwKUBWM.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'link', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1730618573.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'medium.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://medium.com/firebird-technologies/building-auto-analyst-a-data-analytics-ai-agentic-system-3ac2573dcaf0?source=user_profile_page---------7-------------8e57bdd016b9---------------', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?auto=webp&s=8e8c15906d4635566d4194b5a768beb0ffa5fcd3', 'width': 1200, 'height': 678}, 'resolutions': [{'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=108&crop=smart&auto=webp&s=cc8243a20b3ddfd78040b065b4d271fa9a32802f', 'width': 108, 'height': 61}, {'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=216&crop=smart&auto=webp&s=f53fbb3530b8c690eca1126b07fc2f8b65ea2b77', 'width': 216, 'height': 122}, {'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=320&crop=smart&auto=webp&s=34d6d1e6ed6fdcc2f3c0c6ada4a3c064ac507d6f', 'width': 320, 'height': 180}, {'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=640&crop=smart&auto=webp&s=176a74000cbddae2ae4411428019bc4d3d1ed768', 'width': 640, 'height': 361}, {'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=960&crop=smart&auto=webp&s=b925d8c618cc9b312ec8c8203f7a319a547730fa', 'width': 960, 'height': 542}, {'url': 'https://external-preview.redd.it/CCeqbiwAxj5jpdFfBU9zlDPsofn_5qHeFxHxyTYeLYY.jpg?width=1080&crop=smart&auto=webp&s=88bf0204c498228d0424260a73336b9867843ebd', 'width': 1080, 'height': 610}], 'variants': {}, 'id': 'VHsC-xkBIOaRFP8eFIJIzPxHl7nvUegiR6q0IvdJeF8'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1gihj0t', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='AccountOk2272'), 'discussion_type': None, 'num_comments': 1, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gihj0t/building_autoanalyst_a_data_analytics_ai_agentic/', 'stickied': False, 'url': 'https://medium.com/firebird-technologies/building-auto-analyst-a-data-analytics-ai-agentic-system-3ac2573dcaf0?source=user_profile_page---------7-------------8e57bdd016b9---------------', 'subreddit_subscribers': 226170, 'created_utc': 1730618573.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.552+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hulu accidentally dumped a \\~10 page(unformatted) Json on me, not sure where to go with this but does anyone want it?', 'author_fullname': 't2_nlx8s6wx9', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Giant Json from Hulu', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1gj3mab', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.86, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Open Source', 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730685873.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hulu accidentally dumped a ~10 page(unformatted) Json on me, not sure where to go with this but does anyone want it?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '3957ca64-3440-11ed-8329-2aa6ad243a59', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#005ba1', 'id': '1gj3mab', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='aflyingskypi3'), 'discussion_type': None, 'num_comments': 5, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1gj3mab/giant_json_from_hulu/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1gj3mab/giant_json_from_hulu/', 'subreddit_subscribers': 226170, 'created_utc': 1730685873.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.553+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': '', 'author_fullname': 't2_c9g6hufqj', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "Reusability in Data Engineering: Holy Grail or Fool's Errand?", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1gj36yv', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.4, 'author_flair_background_color': 'transparent', 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': 'fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b', 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'default', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1730684548.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'carlineng.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://carlineng.com/?postid=holy-grail-data-engineering#blog', 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': 'Data Engineer', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1gj36yv', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='carlineng_'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/dataengineering/comments/1gj36yv/reusability_in_data_engineering_holy_grail_or/', 'stickied': False, 'url': 'https://carlineng.com/?postid=holy-grail-data-engineering#blog', 'subreddit_subscribers': 226170, 'created_utc': 1730684548.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.554+0000] {logging_mixin.py:190} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff97e2b400>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Tech jobs can be crowded or routine, but Data Engineering seems to stand out. Here‚Äôs why:\n\n* **Real Impact**: Working with huge datasets that drive decisions‚Äîthink billions of records powering AI and BI.\n* **Great Pay, Less Competition**: Salaries average around $98,000 in Canada, with senior roles up to $300,000. Plus, fewer applicants compared to other tech roles.\n* **Transferable Skills**: Tools are standardized across industries, making it easy to switch between fields and platforms.\n\nhttps://preview.redd.it/xup1gnvqxqyd1.png?width=1020&format=png&auto=webp&s=91e1b1bb1bdebf4db5fda5b3371742c8bb59204f\n\nCheckout the full video - [https://youtu.be/TDaCueJKznQ](https://youtu.be/TDaCueJKznQ)\n\nWhat do you think - is Data Engineering the path to watch, or is there something better on the horizon?', 'author_fullname': 't2_c3x6xj5p', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Why Data Engineering Is THE Career Choice for 2025\n', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 80, 'top_awarded_type': None, 'hide_score': False, 'media_metadata': {'xup1gnvqxqyd1': {'status': 'valid', 'e': 'Image', 'm': 'image/png', 'p': [{'y': 62, 'x': 108, 'u': 'https://preview.redd.it/xup1gnvqxqyd1.png?width=108&crop=smart&auto=webp&s=c3d9de0ea186f83274236003e75bc5c422ce604d'}, {'y': 124, 'x': 216, 'u': 'https://preview.redd.it/xup1gnvqxqyd1.png?width=216&crop=smart&auto=webp&s=30b0fc7cfc53a2962649ec0634ce35e94e786cb3'}, {'y': 184, 'x': 320, 'u': 'https://preview.redd.it/xup1gnvqxqyd1.png?width=320&crop=smart&auto=webp&s=0c2eccc99bdf524ba3b36158997367d6628026ca'}, {'y': 369, 'x': 640, 'u': 'https://preview.redd.it/xup1gnvqxqyd1.png?width=640&crop=smart&auto=webp&s=a8eb48a531aa8fd71c63ebc1da03090b23b48ad6'}, {'y': 554, 'x': 960, 'u': 'https://preview.redd.it/xup1gnvqxqyd1.png?width=960&crop=smart&auto=webp&s=38c5f31e50362588e51ae757915fb1571b8cd504'}], 's': {'y': 589, 'x': 1020, 'u': 'https://preview.redd.it/xup1gnvqxqyd1.png?width=1020&format=png&auto=webp&s=91e1b1bb1bdebf4db5fda5b3371742c8bb59204f'}, 'id': 'xup1gnvqxqyd1'}}, 'name': 't3_1giwcw9', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.21, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://a.thumbs.redditmedia.com/j33opZcvmsIgi_LgpThWGkUq_El7hIkzuvJMCVRDcQ4.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1730665604.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Tech jobs can be crowded or routine, but Data Engineering seems to stand out. Here‚Äôs why:</p>\n\n<ul>\n<li><strong>Real Impact</strong>: Working with huge datasets that drive decisions‚Äîthink billions of records powering AI and BI.</li>\n<li><strong>Great Pay, Less Competition</strong>: Salaries average around $98,000 in Canada, with senior roles up to $300,000. Plus, fewer applicants compared to other tech roles.</li>\n<li><strong>Transferable Skills</strong>: Tools are standardized across industries, making it easy to switch between fields and platforms.</li>\n</ul>\n\n<p><a href="https://preview.redd.it/xup1gnvqxqyd1.png?width=1020&amp;format=png&amp;auto=webp&amp;s=91e1b1bb1bdebf4db5fda5b3371742c8bb59204f">https://preview.redd.it/xup1gnvqxqyd1.png?width=1020&amp;format=png&amp;auto=webp&amp;s=91e1b1bb1bdebf4db5fda5b3371742c8bb59204f</a></p>\n\n<p>Checkout the full video - <a href="https://youtu.be/TDaCueJKznQ">https://youtu.be/TDaCueJKznQ</a></p>\n\n<p>What do you think - is Data Engineering the path to watch, or is there something better on the horizon?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1giwcw9', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='cryptoyash'), 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1giwcw9/why_data_engineering_is_the_career_choice_for_2025/', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1giwcw9/why_data_engineering_is_the_career_choice_for_2025/', 'subreddit_subscribers': 226170, 'created_utc': 1730665604.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-11-04T03:32:17.591+0000] {python.py:240} INFO - Done. Returned value was: /opt/airflow/data/output/reddit_20241104.csv
[2024-11-04T03:32:17.614+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-11-04T03:32:17.615+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_extraction, run_id=manual__2024-11-04T03:32:15.194919+00:00, execution_date=20241104T033215, start_date=20241104T033216, end_date=20241104T033217
[2024-11-04T03:32:17.647+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2024-11-04T03:32:17.669+0000] {taskinstance.py:3900} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2024-11-04T03:32:17.670+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
